name: GA7 - GKE Deploy & Stress Test

on:
  push:
    branches: ["ga6-cd"]
  workflow_dispatch:

jobs:
  stress-test:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout
        uses: actions/checkout@v3

      - name: Setup kubectl
        uses: azure/setup-kubectl@v3
        with:
          version: 'latest'

      - name: Configure kubeconfig from secret
        env:
          KUBE_CONFIG: ${{ secrets.KUBE_CONFIG }}
        run: |
          echo "$KUBE_CONFIG" > kubeconfig.yaml
          echo "KUBECONFIG=$PWD/kubeconfig.yaml" >> $GITHUB_ENV

      - name: kubectl client ping
        run: |
          kubectl version --client=true
          kubectl get nodes

      # (Re)apply your manifests to be safe
      - name: Apply manifests (deploy & svc)
        run: |
          kubectl apply -f k8s/deploy.yaml
          kubectl rollout status deploy/iris-api --timeout=120s
          kubectl get svc iris-api-svc

      # Create/Update HPA to 1..3 pods @ 50% CPU
      - name: Configure HPA (1..3 @ 50% CPU)
        run: |
          kubectl autoscale deployment iris-api --cpu-percent=50 --min=1 --max=3 || true
          kubectl get hpa

      # Discover the current external IP of the LB
      - name: Get External IP
        id: svc
        run: |
          IP=$(kubectl get svc iris-api-svc -o jsonpath='{.status.loadBalancer.ingress[0].ip}')
          echo "EXTERNAL_IP=$IP" >> $GITHUB_ENV
          echo "External IP: $IP"

      # Install wrk and run POST load test
      - name: Run wrk stress test (POST /predict)
        run: |
          sudo apt-get update && sudo apt-get install -y wrk
          cat > post.lua <<'LUA'
          wrk.method = "POST"
          wrk.body   = '{"sepal_length":5.1,"sepal_width":3.5,"petal_length":1.4,"petal_width":0.2}'
          wrk.headers["Content-Type"] = "application/json"
          LUA
          echo "Load testing http://$EXTERNAL_IP/predict ..."
          wrk -t4 -c400 -d60s -s post.lua http://$EXTERNAL_IP/predict

      # Show HPA status after the load
      - name: HPA & Pods after load
        run: |
          kubectl get hpa
          kubectl get pods -o wide
          kubectl top pods || true
