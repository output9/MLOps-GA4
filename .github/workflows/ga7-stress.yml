name: GA7 - GKE Deploy & Stress Test with HPA

on:
  push:
    branches: ["ga6-cd"]
  workflow_dispatch:

jobs:
  stress-test:
    runs-on: ubuntu-latest
    env:
      GKE_PROJECT: hybrid-shine-474105-e1   # <-- REPLACE with your GCP Project ID
      GKE_CLUSTER: iris-cluster     # <-- REPLACE with your GKE Cluster Name
      GKE_ZONE: us-central1           # <-- REPLACE with your GKE Zone

    steps:
      - name: Checkout repo
        uses: actions/checkout@v4

      - name: üîê Authenticate to GCP
        uses: google-github-actions/auth@v2
        with:
          # This should be a service account key JSON that has the 
          # necessary roles (e.g., GKE Developer, Storage Admin for image push)
          credentials_json: ${{ secrets.GCP_SA_KEY }} 

      - name: ‚òÅÔ∏è Set up Google Cloud CLI (GKE Access)
        uses: google-github-actions/setup-gcloud@v2

      - name: üîë Get GKE Credentials (Fixes the gke-gcloud-auth-plugin error)
        run: |
          gcloud container clusters get-credentials "$GKE_CLUSTER" --zone "$GKE_ZONE" --project "$GKE_PROJECT"
          echo "‚úÖ GKE Credentials successfully configured."

      - name: Verify cluster connection
        run: |
          # This command will now work without the plugin error
          kubectl get nodes

      - name: Apply manifests (Deployment & Service)
        run: |
          echo "üõ† Applying Kubernetes manifests..."
          # Assuming your deployment is in k8s/ and is named 'iris-api'
          kubectl apply -f k8s/deploy.yaml
          kubectl apply -f k8s/service.yaml # <-- Ensure you have a service.yaml
          kubectl rollout status deploy/iris-api --timeout=120s
          kubectl get svc iris-api-svc

      - name: Configure HPA (1->3 pods @ 50% CPU)
        run: |
          # Use kubectl autoscale for simplicity, but ensure k8s/deploy.yaml has resource requests
          kubectl autoscale deployment iris-api --cpu-percent=50 --min=1 --max=3 || true
          echo "HPA configuration complete (Max 3 pods). Starting with 1."
          kubectl get hpa

      - name: Get External IP and Wait for it
        id: svc_ip
        run: |
          echo "Fetching external IP for iris-api-svc..."
          for i in {1..20}; do
            IP=$(kubectl get svc iris-api-svc -o jsonpath='{.status.loadBalancer.ingress[0].ip}')
            if [ -n "$IP" ]; then
              echo "External IP: $IP"
              echo "EXTERNAL_IP=$IP" >> $GITHUB_ENV
              break
            fi
            echo "Waiting for external IP (Attempt $i/20)..."
            sleep 10
          done
          if [ -z "$EXTERNAL_IP" ]; then
            echo "::error::External IP not provisioned within timeout."
            exit 1
          fi

      - name: Run wrk stress test (SCENARIO 1: Auto-scaling Max 3 Pods)
        run: |
          sudo apt-get update && sudo apt-get install -y wrk
          
          cat > post.lua <<'LUA'
          wrk.method = "POST"
          # Ensure your model accepts this format - Use a minimal valid JSON
          wrk.body = '{"sepal_length":5.1,"sepal_width":3.5,"petal_length":1.4,"petal_width":0.2}' 
          wrk.headers["Content-Type"] = "application/json"
          LUA
          
          echo "üöÄ Starting STRESS TEST 1 (Max 3 Pods, High Concurrency - >1000 requests)..."
          # -t4 threads, -c400 connections, -d60s duration (enough time for HPA to scale)
          # Total requests will be > 1000
          wrk -t4 -c400 -d60s -s post.lua http://$EXTERNAL_IP/predict
          
          echo "üìà HPA and Pod Status during scaling:"
          kubectl get hpa
          kubectl get pods -o wide

      - name: Run wrk stress test (SCENARIO 2: Bottleneck - Restricted to 1 Pod)
        run: |
          echo "‚¨áÔ∏è Restricting HPA max_pods to 1 for bottleneck test..."
          # Update the max replicas to 1
          kubectl autoscale deployment iris-api --cpu-percent=50 --min=1 --max=1 --allow-missing || kubectl autoscale deployment iris-api --cpu-percent=50 --min=1 --max=1

          echo "üõë Starting BOTTLENECK STRESS TEST 2 (Max 1 Pod, Very High Concurrency 2000+ requests)..."
          # Increasing connections to 600, aiming for 2000+ requests total
          wrk -t4 -c600 -d30s -s post.lua http://$EXTERNAL_IP/predict || echo "wrk finished (expected high latency/errors)"

          echo "‚ö†Ô∏è Bottleneck HPA and Pod Status (Should show 1/1 replicas):"
          kubectl get hpa
          kubectl get pods -o wide
          
          # Clean up: Reset HPA back to 3
          echo "‚úÖ Resetting HPA max_pods to 3."
          kubectl autoscale deployment iris-api --cpu-percent=50 --min=1 --max=3 --allow-missing || kubectl autoscale deployment iris-api --cpu-percent=50 --min=1 --max=3
